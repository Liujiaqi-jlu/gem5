Urgent TODOs
-------------------------------------------------
1. Fix potential bugs caused by code hacks in coherent_xbar.cc.
2. Use formula in place of hardcoded memory sizes in ccnuma_fs.py.
3. Write driver scripts to run multicore and CC-NUMA experiments.


Normal TODOs
-------------------------------------------------
1. Support running of Linux kernel 3.19.
2. Support running of CPU2006.
3. Test multiple workload mapping and running.
4. Add automated experiment and plot scripting.
5. Specify number of instructions/cycles to be simulated in detailed/FS simulation phase.
6. add custom statistics in gem5 (e.g., formula)


PARSEC
-------------------------------------------------
http://comments.gmane.org/gmane.comp.emulators.m5.users/12503
http://www.cs.utexas.edu/~parsec_m5/
http://www.cs.utexas.edu/~parsec_m5/TR-09-32.pdf
http://www.m5sim.org/PARSEC_benchmarks#Running_PARSEC_in_gem5
https://schen26.wordpress.com/2012/11/16/parsec-on-m5-with-x86_fs/
http://yulistic.com/problems-solutions/230   [Gem5] Make a new boot image


General
-------------------------------------------------
https://github.com/lzyerste/gem5_doc/wiki


gem5 horrors and solutions
-------------------------------------------------
http://www.lowepower.com/jason/gem5-horrors-and-what-we-can-do-about-it.html


NUMA
-------------------------------------------------
http://qa.gem5.org/1395/how-to-simulate-a-numa-system?show=1395#q1395
https://www.mail-archive.com/gem5-users@gem5.org/msg09699.html
https://www.mail-archive.com/gem5-users@gem5.org/msg09709.html
http://t362027.emulators-m5-users.emulatortalk.info/help-cc-numa-in-gem5-t362027.html
https://github.com/djangkrix/gem5

http://search.gmane.org/?query=numa&group=gmane.comp.emulators.m5.users
http://thread.gmane.org/gmane.comp.emulators.m5.users/3927 *
http://thread.gmane.org/gmane.comp.emulators.m5.users/13134
http://thread.gmane.org/gmane.comp.emulators.m5.users/13188
http://thread.gmane.org/gmane.comp.emulators.m5.users/14277
http://thread.gmane.org/gmane.comp.emulators.m5.users/15970
http://thread.gmane.org/gmane.comp.emulators.m5.users/15980

http://thread.gmane.org/gmane.comp.emulators.m5.users/16572 *
http://thread.gmane.org/gmane.comp.emulators.m5.users/17326 *

http://thread.gmane.org/gmane.comp.emulators.m5.users/17738
http://thread.gmane.org/gmane.comp.emulators.m5.users/14663

I just created:
A. a 4 cpu numa system,
B. each cpu connect to a membus and then a dram controller,
C. each dram is 128MB,
D. every two membus is connected to each other by a Cache(in two
directions),
E. with address range set to the slave mebus's address range.
F. IO devices are connected to the first node.


> Hi Faris,
>
> I do not thing there are any existing examples out there. In essence,
> this is what I would suggest (and believe should work):
>
> 1 change an existing script to create two completely separate CC-UMA
> "chiplets" with CPU clusters, along with their L2/L3, membus and
> (multi-channel) DRAM controller
> 2 connect these two blobs with a "numa cache" in each direction, from
> membus to membus. Configured right, this will allow the CPUs in one of
> the chiplets to talk to the DRAMs in the other in a coherent fashion.
>
> I hope that provides enough information to get you started.
>
> Andreas


Hi Faris,
>
>             The short answer is yes. You will have to manually adapt
>             se.py or fs.py based on your needs. You could, for
>             example, create two clusters of CPUs, each with their own
>             LLC and memory controllers (and memory ranges), and then
>             connect their membus instances with a "glue" cache.
>
>             Andreas